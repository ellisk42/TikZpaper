%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Jacobs Landscape Poster
% LaTeX Template
% Version 1.1 (14/06/14)
%
% Created by:
% Computational Physics and Biophysics Group, Jacobs University
% https://teamwork.jacobs-university.de:8443/confluence/display/CoPandBiG/LaTeX+Poster
% 
% Further modified by:
% Nathaniel Johnston (nathaniel@njohnston.ca)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[final]{beamer}

\usepackage{listings}
\usepackage{amsmath}
\usepackage{verbatim}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{etoolbox}
\usepackage{booktabs}
\AtBeginEnvironment{algorithm}{%
  \setlength{\columnwidth}{\linewidth}%
}

\usepackage[scale=1.24]{beamerposter} % Use the beamerposter package for laying out the poster
\usepackage{tipa}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usetheme{confposter} % Use the confposter theme supplied with this template
\usepackage{sidecap}
\setbeamercolor{block title}{fg=ngreen,bg=white} % Colors of the block titles
\setbeamercolor{block body}{fg=black,bg=white} % Colors of the body of blocks
\setbeamercolor{block alerted title}{fg=white,bg=dblue!70} % Colors of the highlighted block titles
\setbeamercolor{block alerted body}{fg=black,bg=dblue!10} % Colors of the body of highlighted blocks
% Many more colors are available for use in beamerthemeconfposter.sty

%-----------------------------------------------------------
% Define the column widths and overall poster size
% To set effective sepwid, onecolwid and twocolwid values, first choose how many columns you want and how much separation you want between columns
% In this template, the separation width chosen is 0.024 of the paper width and a 4-column layout
% onecolwid should therefore be (1-(# of columns+1)*sepwid)/# of columns e.g. (1-(4+1)*0.024)/4 = 0.22
% Set twocolwid to be (2*onecolwid)+sepwid = 0.464
% Set threecolwid to be (3*onecolwid)+2*sepwid = 0.708

\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\usepackage{dsfont}

\newtheorem{proposition}{Proposition}
\newcommand{\expect}{\mathds{E}} %{{\rm I\kern-.3em E}}
\newcommand{\probability}{\mathds{P}} %{{\rm I\kern-.3em P}}
\newcommand{\indicator}{\mathds{1}} %{{\rm I\kern-.3em P}}

%\newtheorem{definition}{Definition}

\newlength{\sepwid}
\newlength{\onecolwid}
\newlength{\twocolwid}
\newlength{\threecolwid}
\setlength{\paperwidth}{76in} % A0 width: 46.8in
\setlength{\paperheight}{41in} % NIPS16 : 36
\setlength{\sepwid}{0.024\paperwidth} % Separation width (white space) between columns
\setlength{\onecolwid}{0.22\paperwidth} % Width of one column
\setlength{\twocolwid}{0.464\paperwidth} % Width of two columns
\setlength{\threecolwid}{0.708\paperwidth} % Width of three columns
\setlength{\topmargin}{-0.5in} % Reduce the top margin size
%-----------------------------------------------------------

\usepackage{etoolbox}
\makeatletter
\patchcmd{\beamer@@tmpl@headline}{wd=47in}{wd=75in}{}{}
\makeatother

\usepackage{graphicx}  % Required for including images
\usepackage{verbatim}
\usepackage{booktabs} % Top and bottom rules for tables
\usepackage{fancyvrb}
\DeclareMathOperator*{\argmin}{arg\,min} % thin space, limits underneath in displays
% \DeclareMathOperator{\argmin}{argmin} % no space, limits underneath in displays
\DeclareMathOperator*{\argmax}{arg\,max} % thin space, limits underneath in displays
% \DeclareMathOperator{\argmax}{argmax} % no space, limits underneath in displays

\newcommand{\expect}{\mathds{E}} %{{\rm I\kern-.3em E}}
\newcommand{\probability}{\mathds{P}} %{{\rm I\kern-.3em P}}
\newcommand{\indicator}{\mathds{1}} %{{\rm I\kern-.3em P}}

\begin{SaveVerbatim}[]{ListSketch}
Program ::=
  (if Bool List
    (append RecursiveList
            RecursiveList
            RecursiveList))
Bool ::= (<= Int) | (>= Int)
Int  ::= 0 | (1+ Int) | (1- Int)
       | (length List) | (head List)
List ::= nil | (filter Bool List)
      | X | (tail List) | (list Int)
RecursiveList ::= List
                | (recurse List)
\end{SaveVerbatim}

\begin{SaveVerbatim}[]{TextSketch}
Program ::= Term | Program + Term
Term    ::= String | substr(Pos,Pos)
Pos     ::= Number
         |  pos(String,String,Number)
Number  ::= 0 | 1 | 2 | ... 
         | -1 | -2 | ...
String  ::= Character 
         |  Character + String
Character ::= a | b | c | ...
\end{SaveVerbatim}



\usepackage{wrapfig}

%----------------------------------------------------------------------------------------
%	TITLE SECTION 
%----------------------------------------------------------------------------------------
\usepackage{stmaryrd}
\newcommand{\tuple}[1]{\ensuremath{\left \langle #1\right \rangle}}
\newcommand{\sem}[1]{[\mkern-6mu[#1]\mkern-6mu]} %\newcommand{\sem}[1]{\llbracket #1\rrbracket}

\usetikzlibrary{trees}
\usetikzlibrary{fit}
\usetikzlibrary{calc}
\usetikzlibrary{bayesnet}

\usepackage{arydshln}

\usepackage[normalem]{ulem}
\newcommand{\theSystem}{\textsc{DreamCoder}}
\title{Learning to Infer Graphics Programs from Hand-Drawn Images} % Poster title

\author{Kevin Ellis, Daniel Ritchie, Lucas Morales, Mathias Sabl\'e Meyer,  Joshua B. Tenenbaum, Armando Solar-Lezama} % Author(s)

\institute{Massachusetts Institute of Technology \& Brown University} % Institution(s)

%----------------------------------------------------------------------------------------

\begin{document}
\addtobeamertemplate{headline}{} 
{\begin{tikzpicture}[remember picture, overlay]
     \node [anchor=north east, inner sep=3cm]  at (current page.north east)
           {\includegraphics[height=7cm]{figures/csail.png}};
                \node [anchor=north west, inner sep=3cm]  at (current page.north west)
     {\includegraphics[height=5cm]{figures/bcs.png}};
\end{tikzpicture}}

\addtobeamertemplate{block end}{}{\vspace*{2ex}} % White space under blocks
\addtobeamertemplate{block alerted end}{}{\vspace*{2ex}} % White space under highlighted (alert) blocks

\setlength{\belowcaptionskip}{2ex} % White space under figures
\setlength\belowdisplayshortskip{2ex} % White space under equations

\begin{frame}[t] % The whole poster is enclosed in one beamer frame

\begin{columns}[t] % The whole poster consists of three major columns, the second of which is split into two columns twice - the [t] option aligns each column's content to the top

\begin{column}{\sepwid}\end{column} % Empty spacer column

\begin{column}{\onecolwid} % The first column

%----------------------------------------------------------------------------------------
%	OBJECTIVES
%----------------------------------------------------------------------------------------

  \begin{alertblock}{Hand drawings to high-level graphics procedures}
    Convert image of hand drawing into $\LaTeX$ (left pair: top white is drawing, bottom black is $\LaTeX$ render). Infer high-level graphics program from drawing: captures higher-order structure like repetition, motifs, symmetries.
    \includegraphics[width = \textwidth]{firstPageExample.pdf}
\end{alertblock}

\begin{block}{Two-Stage Pipeline}
\hspace{-5cm}  \includegraphics[width = 50cm]{pipeline.pdf}
  
  Black arrows: Top--down generative model; Program$\to$Spec$\to$Image. {\color{red}Red} arrows: Bottom--up inference procedure. \textbf{Bold:} Random variables (image/spec/program)
\end{block}

%----------------------------------------------------------------------------------------
%	INTRODUCTION
%----------------------------------------------------------------------------------------

\begin{block}{Parsing Images into Drawing Commands (specs)}
\vspace{-3cm}  \includegraphics[width = 40cm]{architecture.pdf}

{\small   \textcolor{blue}{Blue}: network inputs. Black: network operations. \textcolor{red}{Red}: draws from a multinomial. \texttt{Typewriter font}: network outputs. Renders on a $16\times 16$ grid, shown in \textcolor{gray}{gray}. STN: differentiable attention mechanism. \textbf{Combined with stochastic search (Sequential Monte Carlo)}}

%\begin{figure}[h]\centering
  \begin{minipage}[c]{0.49\textwidth} 
    \centering  \includegraphics[width = \textwidth]{figures/drawingAccuracy.png}            \vspace{-0.5cm} 
  \end{minipage}\hfill%
      \begin{minipage}[c]{0.5\textwidth} 
  {\small (Left) NN outputs vs ground truth on hand drawings (measured by IoU), as we consider larger sets of samples (1, 5, 100).
     (a) for 63\% of drawings the model's top prediction is exactly correct; (b) for 70\% of drawings the ground truth is in the top 5 model predictions; (c) for 4\% of drawings all of the model outputs have no overlap with the ground truth. Red: the full model. Other colors: ablations. Model is at ceiling for synthetic $\LaTeX$ output.}
      \end{minipage}

%\end{figure}
\end{block}

%% \begin{block}{Problem Framing}
%%   \begin{itemize}
%%   \item Sketch specifies a large but finite set of programs, $S$
%%   \item Program description length: $\lvert x \rvert$ for $x\in S$
%%   \item Prior over programs: $\propto 2^{- \lvert x \rvert }$
%%   \item Posterior over programs: call this $p(x)$, defined as $\propto 2^{- \lvert x \rvert } \mathds{1}[x \text{ consistent with input/output examples}]$
%%   \end{itemize}
%%   Our goal then  is to sample from $p(\cdot)$.
%% \end{block}



%------------------------------------------------



%----------------------------------------------------------------------------------------

\end{column} % End of the first column

\begin{column}{\sepwid}\end{column} % Empty spacer column

\begin{column}{\twocolwid} % Begin a column which is two columns wide (column 2)

\begin{columns}[t,totalwidth=\twocolwid] % Split up the two columns wide column

\begin{column}{\onecolwid}\vspace{-.6in} % The first column within column 2 (column 2.1)

%----------------------------------------------------------------------------------------
%	MATERIALS
%----------------------------------------------------------------------------------------
%

%%  \begin{alertblock}{Bayesian Program Learning \& other approaches} %
    %% Why might a learner represent knowledge as a program,
    %% rather than the representations popular in much of machine learning,
    %% such as a large matrix of weights or a graphical model?
    %% Programs (probabilistic or deterministic)
    %% excel at representing knowledge that is (1) symbolic; (2) compositional; or (3) higher-order.
    %% We are motivated by the success of program induction
    %% in both AI domains,
    %% like semantic parsing and programming by demonstration,
    %% and in cognitive modeling,
    %% like intuitive theory learning~\cite{logical}.
%%\end{alertblock}
  
  \begin{block}{Domain-Specific Language for Graphics Programs}
 We allow loops (\texttt{for}) with conditionals (\texttt{if}), vertical/horizontal reflections (\texttt{reflect}), variables (Var) and affine transformations ($\mathbb{Z}\times$Var\texttt{+}$\mathbb{Z}$).
  \begin{tabular}{rl}\toprule
  Program$\to$&Statement; $\cdots$; Statement\\
  Statement$\to$&\texttt{circle}(Expression,Expression)\\
  Statement$\to$&\texttt{rectangle}(Expression,Expression,Expression,Expression)\\
  Statement$\to$&\texttt{line}(Expression,Expression,Expression,Expression,Boolean,Boolean)\\
  Statement$\to$&\texttt{for}$(0\leq \text{Var}  < \text{Expression})$\texttt{ \{ if }$(\text{Var} > 0)$\texttt{ \{ }Program\texttt{ \}; }Program\texttt{ \}}\\
  Statement$\to$&\texttt{reflect}$(\text{Axis})$\texttt{ \{ }Program\texttt{ \}}\\
  Expression$\to$&$\mathbb{Z}\times$Var\texttt{+}$\mathbb{Z}$\\
%  Var$\to$&A free (unused) variable\\
  Axis$\to$&\texttt{X = }$\mathbb{Z}$ | \texttt{Y = }$\mathbb{Z}$\\
    $\mathbb{Z}\to$&an integer\\\bottomrule
  \end{tabular}
  \end{block}

  \begin{block}{Learning \& Constraint-Based Program Synthesis}
    \textbf{Sketch}: state-of-the-art program synthesizer. Solar-Lezama 2008.\\Solves, for spec $S$ \& program $p$:
$$
  \text{program}(S) = \argmin_{p\in \text{DSL, s.t. }p \text{ consistent w/ } S} \text{cost}(p)\label{programObjective}
$$
  \textbf{Learn policy $\pi_\theta$ to accelerate program synthesizer's search.}\\ $\pi_\theta(\cdot |S) \in  \Delta^\Sigma$,
  where $\Sigma\ni\sigma $ a set of synthesis problem (i.e., $\sigma \in \Sigma $ is a sketch)

%%   \noindent\textbf{Definition: Bias-optimality.}  (c.f. Schmidhuber 2004)
%%    A search algorithm is $n$-\emph{bias optimal}
%% with respect to a distribution $\probability_{\text{bias}}[\cdot ]$ if it is
%% guaranteed to find a solution in $\sigma $ after searching for at least time
%% $n\times\frac{t(\sigma )}{\probability_{\text{bias}}[\sigma ]}$, where $t(\sigma )$ is the time it
%% takes to verify that $\sigma $ contains a solution to the
%% search problem.

%% Here, $\probability_{\text{bias}}[\cdot ] = \pi_\theta(\cdot |S)$.
\textbf{Inference strategy}: Timeshare according to $\pi_\theta(\cdot |S)$, like in Levin Search
  \begin{figure}\centering
  \begin{tikzpicture}[scale=3]
    \node[anchor = west] at (0,5.25) {Entire program search space};
    \draw[fill = yellow,fill opacity = 0.15,draw = black] (0,0) rectangle (5,5);
    \draw [fill = yellow, opacity = 0.2] (0,0)--(0,2)--(4,0)--(0,0);
    \draw [fill = yellow, opacity = 0.4,cycle] (0,5)--(0,1)--(3,5);
    \draw [fill = yellow, opacity = 0.6,cycle] (2.5,5)--(3.2,0)--(5,0)--(5,5);
    \draw (0,2) -- node[below,sloped]{short programs} (4,0);
    \draw (0,2) -- node[above,sloped]{long programs} (4,0);
    \draw (2.5,5) -- node[above,sloped]{programs w/ reflections} (3.2,0);
    \draw (0,1) -- node[above,sloped]{ programs w/ loops} (3,5);
    \node(p1)[anchor =west ] at (5.5,3.5) {$\pi_\theta(\text{short, no loop/reflect}) = $};
    \draw [fill = yellow, fill opacity = 0.2,draw = black]  ([xshift = 0cm,yshift = -0.2cm]p1.east) rectangle ([xshift = 0.4cm,yshift = 0.2cm]p1.east);
    \node(p2)[anchor =west ] at ([yshift = -0.5cm]p1.west) {$\pi_\theta(\text{long, loops}) = $};
    \draw [fill = yellow, fill opacity = 0.4,draw = black]  ([xshift = 0cm,yshift = -0.2cm]p2.east) rectangle ([xshift = 0.4cm,yshift = 0.2cm]p2.east);
    \node(p3)[anchor =west ] at ([yshift = -0.5cm]p2.west) {$\pi_\theta(\text{long, no loop/reflect}) = $};
    \draw [fill = yellow, fill opacity = 0.15,draw = black]  ([xshift = 0cm,yshift = -0.2cm]p3.east) rectangle ([xshift = 0.4cm,yshift = 0.2cm]p3.east);
    \node(p4)[anchor =west ] at ([yshift = -0.5cm]p3.west) {$\pi_\theta(\text{long, reflects}) = $};
    \draw [fill = yellow, fill opacity = 0.6,draw = black]  ([xshift = 0cm,yshift = -0.2cm]p4.east) rectangle ([xshift = 0.4cm,yshift = 0.2cm]p4.east);
    \node(p5)[anchor =west ] at ([yshift = -0.5cm]p4.west) {\emph{etc.}};
  \end{tikzpicture}
  \caption{The bias-optimal search algorithm divides the entire (intractable) program search space in to (tractable) program subspaces (written $\sigma $), each of which contains a restricted set of programs. For example, one subspace might be short programs which don't loop. The policy $\pi$ predicts a distribution over program subspaces:  weight assigned by $\pi$ indicated by  shading}
\end{figure}

Differentiable loss ($\mathcal{D}$ a corpus of synthesis problems):
\begin{align}
\textsc{Loss}(\theta ; \mathcal{D})& =  \expect_{S\sim\mathcal{D}}\left[ \min_{\sigma\in \text{\textsc{Best}}(S)}\frac{t(\sigma | S)}{\pi_\theta (\sigma | S)}\right] + \lambda \Vert\theta\Vert_2^2\label{policyLoss}\\
\text{where }  \sigma \in\text{\textsc{Best}}(S) &\text{ if  a minimum cost program for }S \text{ is in }\sigma .\nonumber %\text{cost}(\text{program}(p)) = \min_{p\in \sigma \text{, s.t. }p\text{ evaluates to }S} \text{cost}(p) \nonumber
\end{align}

\includegraphics[width = \textwidth]{figures/policyComparison_basic_DC+bias_20.png}

Time to synthesize a minimum cost program. Sketch: out-of-the-box performance of Sketch. DC: Deep--Coder style baseline that predicts program components, trained like Balog 2016. Oracle:  upper bounds  the performance of any bias--optimal search policy. $\infty = $ timeout. Red dashed line is median time
  \end{block}



%----------------------------------------------------------------------------------------

\end{column} % End of column 2.1

\begin{column}{\onecolwid}\vspace{-.6in} % The second column within column 2 (column 2.2)

%----------------------------------------------------------------------------------------
%	METHODS
%----------------------------------------------------------------------------------------

  \begin{block}{Extrapolating Drawings}
    Automatically extrapolate by increasing loop bounds. Top white: Hand drawing. Bottom black: extrapolation.
    
      \includegraphics[width = \textwidth]{figures/extrapolationMatrix1.png}\\
  \includegraphics[width = \textwidth]{figures/extrapolationMatrix2.png}\\
  \includegraphics[width = \textwidth]{figures/extrapolationMatrix3.png}  \\
\end{block}

  \begin{block}{Example System Outputs}
\includegraphics[width = \textwidth]{examplePrograms.pdf} 
\end{block}

\begin{block}{Learning from very few examples}
\begin{figure}[h]\centering
  \begin{minipage}{0.45\textwidth}\centering
    \includegraphics[width=\textwidth]{smallFractionSolving.png}
  \caption{Results averaged across 19 problems. Solid: \theSystem{} . Dashed: enumerating 100 programs. Dotted: MDL.}\label{flashPerformance}        \end{minipage}%
\hspace{0.025\textwidth}\begin{minipage}{0.45\textwidth}\centering
    \includegraphics[width=0.7\textwidth]{small_mdl.png}
    \caption{MDL learner vs \theSystem{} on one-shot learning. Predictions marginalize out the program.}\label{mdl}
  \end{minipage}
\end{figure}

%\textbf{Multiple explanations aids one-shot learning.} After a single example, the shortest program is probably not correct -- but one of the top sampled \emph{behaviors} (marginalizing over the program) might be.

\textbf{Good performance needs tilt correction.} w/o low-tilt approximation, get no samples for any of these problems after an hour, vs $\approx 1$ minute w/ \theSystem



\end{block}

%% \begin{block}{The Cost of Sampling}
%%   Amortized cost of 100 samples from \theSystem :
  
%%   \vspace{1cm}

%%   \hspace{9cm}\vspace{1cm}    \begin{tabular}{lll}\toprule
%%      1 example\hspace{0.9cm}      &  2 examples\hspace{0.9cm}          &     3 examples\\\midrule
%% $84 \pm 3$ sec &$21 \pm 1$ sec & $49\pm 3$ sec
%% \end{tabular}

%% \textbf{Good performance needs tilt correction.} w/o low-tilt approximation, get no samples for any of these problems after an hour!

%% \textbf{Can closely approximate posterior with little overhead.}

%% %\vspace{-2.5cm}
%% \begin{tabular}{cl}
%%   \begin{tabular}{c}
%%     \includegraphics[width=25cm]{trim-trade-off.png}
%%     \end{tabular}&
%%   \begin{tabular}{l}
%%     \parbox{15cm}{Accuracy (colored contours) vs Performance (monochrome cells) trade-off; upper bounds plotted. Performance measured in expected solver invocations; accuracy measured in log KL divergence.}
%%     \end{tabular}
%% \end{tabular}
%% %\end{figure}

%%   \end{block}
%----------------------------------------------------------------------------------------

\end{column} % End of column 2.2

\end{columns} % End of the split of column 2 - any content after this will now take up 2 columns width


%----------------------------------------------------------------------------------------

\begin{columns}[t,totalwidth=\twocolwid] % Split up the two columns wide column again

 % End of column 2.1

\begin{column}{\onecolwid} % The second column within column 2 (column 2.2)

%----------------------------------------------------------------------------------------
%	RESULTS
%----------------------------------------------------------------------------------------


%----------------------------------------------------------------------------------------

\end{column} % End of column 2.2

\end{columns} % End of the split of column 2

\end{column} % End of the second column

\begin{column}{\sepwid}\end{column} % Empty spacer column

\begin{column}{\onecolwid} % The third column

%----------------------------------------------------------------------------------------
%	CONCLUSION
%----------------------------------------------------------------------------------------

  \begin{alertblock}{NEW: Wake-Sleep DSL learning with \theSystem}

    \begin{minipage}[c]{0.45\textwidth}
    \begin{itemize}
    \item \textbf{Wake:} Synthesize programs from DSL + neural net (`recognition model') to guide search
    \item \textbf{Sleep-G:} Grow DSL, using grammar induction algorithms
    \item \textbf{Sleep-R:} Train neural net on programs found during waking (`experience replay') and samples from DSL (`dreaming')
    \end{itemize}
    \end{minipage}%
    \begin{minipage}[c]{0.48\textwidth}      
    \begin{tikzpicture}[scale=3,line width=1.5mm]
    \begin{scope}[shift = {(1,-1)}]
    \node[align = center](synthesis) at (6,4) {Search for \\programs: $p$};
    \node[align = center](DSL) at (3,1) {DSL: $\mathcal{D}$};
    \node[align = center](recognitionModel) at (9,1) {Recognition \\model: $Q$};

    \draw [->] (synthesis.-120) to[out = -150,in = 60] node[below,rotate = 45,align = center]{{\footnotesize Trains}\\{\footnotesize (Sleep-G)}} (DSL.30);
    \draw [->] (synthesis.-60) to[out = -30,in = 120] node[below,rotate=-45,align = center]{{\footnotesize Trains}\\{\footnotesize (Sleep-R)}} (recognitionModel.150);
    \draw [->] (DSL.east) to[out = -30,in = 210] node[above, align = center]{{\footnotesize Trains}\\{\footnotesize (Sleep-R)}} (recognitionModel.west);

    \draw [->,dashed] (DSL.north) to[out = 90,in = 180] node[fill=dblue!10,align = center]{  \footnotesize{Inductive bias}\\\footnotesize{(Wake)}} (synthesis.west);
    \draw [->,dashed] (recognitionModel.north) to[out = 90,in = 0] node[fill=dblue!10,align = center]{{\footnotesize Makes tractable}\\{\footnotesize (Wake)}} (synthesis.east);
  \end{scope}
    \end{tikzpicture}
      \end{minipage}
  \end{alertblock}

\begin{block}{\theSystem~outputs for three different task domains}

\hspace{-2cm}\includegraphics[width = 1.15\textwidth]{figures/3DSL.png}
{\small Top: Tasks from three domains we apply our algorithm to, each followed by the programs \theSystem~ discovers for them. Bottom: Several examples from learned DSL. Notice that learned DSL primitives can call each other, and that \theSystem~rediscovers higher-order functions like \code{filter} ($f_1$ under List Functions)}
\end{block}

%----------------------------------------------------------------------------------------
%	ADDITIONAL INFORMATION
%----------------------------------------------------------------------------------------

\begin{block}{Bayesian framing}

  \begin{minipage}[c]{0.45\textwidth}
      \begin{tikzpicture}[scale=4,line width=1.5mm]

  \node[latent,scale=3] at (3.5,3) (dx){$\mathcal{D}$};
  \node[latent,scale=3] at ([xshift=2cm]dx) (zp){$p_n$};
  \node[obs,scale=3] at ([xshift=2cm]zp) (xp) {$x_n$};
  \plate {}{(zp)(xp)}{};
%  \node[align = center] at ([yshift = -1.2cm,xshift = 1cm]xp.east) {(b) \\recognition model};
  \draw [->,red] (xp.south) to[out = -90,in = -90] node(nn){} (zp.south);
%  \draw [->,red] (tx.west) -- (zp.east);
  \draw [->] (dx.east) -- (zp.west);
  \draw [->] (zp.east) -- (xp.west);

  \node at (nn) {
    \begin{tikzpicture}[x=2.5cm,y=1.25cm,transform canvas={scale=0.5,shift={+(-1,2.5)}}]
      \tikzstyle{neuron}=[circle,fill=blue!50,minimum size=20pt]
      \fill[fill=white] (-0.25,-0.5) rectangle (2.25,-4.5);
      \node[rectangle] at (1,1) {};
      \foreach \name / \y in {1,...,4}
          \node[neuron] (I-\name) at (0,-\y) {};
      \foreach \name / \y in {1,...,3}
          \node[neuron] (H-\name) at (1,-\y-0.5) {};
      \foreach \name / \y in {1,...,4}
          \node[neuron] (O-\name) at (2,-\y) {};
      \foreach \source in {1,...,4}
          \foreach \dest in {1,...,3}
              \draw [-latex] (I-\source) -- (H-\dest);
      \foreach \source in {1,...,3}
          \foreach \dest in {1,...,4}
              \draw [-latex] (H-\source) -- (O-\dest);
    \end{tikzpicture}
  };
  \node[shift={+(0,-1.7)}] at (nn) { $Q$  };



  


      \end{tikzpicture}
      $x_n$: program synthesis problem. $p_n$: (latent) program solving $x_n$. $Q(p|x)$: (learned) neural recognition model. $\mathcal{D}$: (latent) DSL.
  \end{minipage}\qquad%
  \begin{minipage}[c]{0.4\textwidth}
    
  $$
\underbrace{p_n^* =   \argmax_{p_n}\probability[x_n|p_n]\probability[p_n|\mathcal{D}^*]}_{\text{\textbf{Wake}}}
$$
\vspace{0.5cm}
$$
\underbrace{\mathcal{D}^* = \argmax_{\mathcal{D}}    \probability[\mathcal{D}]\prod_n\sum_{p_n}\probability[x_n|p_n]\probability[p_n|\mathcal{D}]}_{\textbf{\text{Sleep-G}}}
$$
\vspace{0.5cm}
$$\underbrace{Q^* = \argmin_Q \text{KL}\left(\probability[p|x,\mathcal{D}] || Q(p|x)\right) }_{\text{\textbf{Sleep-R}}}$$
    \end{minipage}

  
    
\end{block}

%----------------------------------------------------------------------------------------
%	REFERENCES
%----------------------------------------------------------------------------------------

\setbeamercolor{block title}{fg=red,bg=white} % Change the block title color
%% \begin{block}{References}

%%   %\nocite{*} % Insert publications even if they are not cited in the poster
%%   \renewcommand{\refname}{\vspace{-0.8em}}
%%           \bibliographystyle{plain}
%%           \bibliography{main}
%% %\small{\bibliographystyle{plain}
%% %\bibliography{main}}

%% \end{block}

%----------------------------------------------------------------------------------------
%	ACKNOWLEDGEMENTS
%----------------------------------------------------------------------------------------

\setbeamercolor{block title}{fg=red,bg=white} % Change the block title color

%% \begin{block}{Acknowledgements}

%% \small{\rmfamily{We are grateful for feedback from Adam Smith, Kuldeep Meel, and our anonymous reviewers.
%% Work supported by AFOSR award FA9550-16-1-0012.}} \\

%% \end{block}

%----------------------------------------------------------------------------------------
%	CONTACT INFORMATION
%----------------------------------------------------------------------------------------


%----------------------------------------------------------------------------------------

\end{column} % End of the third column

\end{columns} % End of all the columns in the poster

\end{frame} % End of the enclosing frame

\end{document}

